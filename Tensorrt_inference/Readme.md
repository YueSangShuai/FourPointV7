# ***Tensorrt推理***

该目录包括trt模型和pt模型速度的测试，trt模型的推理以及trt模型输入和输出结果的判断  
可以用官方的trtexec进行onnx的转换
trt模型推理的预处理部分我写的像坨狗屎所以导致整体帧率不高，懒得改了后面会写c++版本的推理用python看一下模型推理的结果而已  
其中trt_inference采用的是官方的onnx转Tensorrt的推理其中的输出有四层可以使用check_trt_model.py这个脚本查看  
而trt_inferenceV2将其中的三个无用的检测层删除，具体模型的转换之后会放在c++版本的推理中
